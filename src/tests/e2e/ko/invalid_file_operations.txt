ENTRYPOINT DEBUG ACTIVE: src/shtest_compiler/shtest.py loaded
[DEBUG] Loaded patterns: ['step', 'action_result', 'action_only', 'result_only', 'comment']
[DEBUG] Pattern for step: ^(?:Étape|Etape|Step)\s*:\s*(.*)$
[DEBUG] Pattern for action_result: ^Action\s*:\s*(.*?)(?:\s*;\s*(?:R[ée]sultat|Resultat)\s*:\s*(.*)|\s*R[ée]sultat\s*:\s*(.*))$
[DEBUG] Pattern for action_only: ^Action\s*:\s*(.*)$
[DEBUG] Pattern for result_only: ^R[ée]sultat\s*:\s*(.*)$
[DEBUG] Pattern for comment: ^\s*#.*$
[DEBUG] Added STEP tokenizer with pattern: ^(?:Étape|Etape|Step)\s*:\s*(.*)$
[DEBUG] Added ACTION_RESULT tokenizer with pattern: ^Action\s*:\s*(.*?)(?:\s*;\s*(?:R[ée]sultat|Resultat)\s*:\s*(.*)|\s*R[ée]sultat\s*:\s*(.*))$
[DEBUG] Added ACTION_ONLY tokenizer with pattern: ^Action\s*:\s*(.*)$
[DEBUG] Added RESULT_ONLY tokenizer with pattern: ^R[ée]sultat\s*:\s*(.*)$
[DEBUG] Added COMMENT tokenizer with pattern: ^\s*#.*$
[DEBUG] Added FallbackTokenizer
[DEBUG] Parsing text with 12 lines
[DEBUG] Lexing text with 12 lines
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=# Test with invalid file operations at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=# Test with invalid file operations at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=# Test with invalid file operations at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=# Test with invalid file operations at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding token type=TokenType.COMMENT, value=# Test with invalid file operations, result=None, original=# Test with invalid file operations at line 1
[DEBUG] Yielding token: COMMENT@1:0 '# Test with invalid file operations'
[DEBUG] RegexTokenizer.tokenize: Yielding token type=TokenType.STEP, value=Test invalid file path, result=('Test invalid file path',), original=Étape: Test invalid file path at line 1
[DEBUG] Yielding token: STEP@1:0 'Test invalid file path' -> '('Test invalid file path',)'
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Action: Créer le fichier: /invalid/path/with/special/chars/\0\1\2 at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Action: Créer le fichier: /invalid/path/with/special/chars/\0\1\2 at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding token type=TokenType.ACTION_ONLY, value=Créer le fichier: /invalid/path/with/special/chars/\0\1\2, result=('Créer le fichier: /invalid/path/with/special/chars/\\0\\1\\2',), original=  Action: Créer le fichier: /invalid/path/with/special/chars/\0\1\2 at line 1
[DEBUG] Yielding token: ACTION_ONLY@1:0 'Créer le fichier: /invalid/path/with/special/chars/\0\1\2' -> '('Créer le fichier: /invalid/path/with/special/chars/\\0\\1\\2',)'
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le fichier existe at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le fichier existe at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le fichier existe at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le fichier existe at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le fichier existe at line 1
[DEBUG] Yielding token: TEXT@1:0 'Vérifier: Le fichier existe'
[DEBUG] RegexTokenizer.tokenize: Yielding EMPTY token at line 1
[DEBUG] Yielding token: EMPTY@1:0 ''
[DEBUG] RegexTokenizer.tokenize: Yielding token type=TokenType.STEP, value=Test invalid directory, result=('Test invalid directory',), original=Étape: Test invalid directory at line 1
[DEBUG] Yielding token: STEP@1:0 'Test invalid directory' -> '('Test invalid directory',)'
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Action: Créer le dossier: /root/system/directory/that/should/fail at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Action: Créer le dossier: /root/system/directory/that/should/fail at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding token type=TokenType.ACTION_ONLY, value=Créer le dossier: /root/system/directory/that/should/fail, result=('Créer le dossier: /root/system/directory/that/should/fail',), original=  Action: Créer le dossier: /root/system/directory/that/should/fail at line 1
[DEBUG] Yielding token: ACTION_ONLY@1:0 'Créer le dossier: /root/system/directory/that/should/fail' -> '('Créer le dossier: /root/system/directory/that/should/fail',)'
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le dossier existe at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le dossier existe at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le dossier existe at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le dossier existe at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le dossier existe at line 1
[DEBUG] Yielding token: TEXT@1:0 'Vérifier: Le dossier existe'
[DEBUG] RegexTokenizer.tokenize: Yielding EMPTY token at line 1
[DEBUG] Yielding token: EMPTY@1:0 ''
[DEBUG] RegexTokenizer.tokenize: Yielding token type=TokenType.STEP, value=Test invalid file copy, result=('Test invalid file copy',), original=Étape: Test invalid file copy at line 1
[DEBUG] Yielding token: STEP@1:0 'Test invalid file copy' -> '('Test invalid file copy',)'
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Action: Copier le fichier: nonexistent_source.txt vers: destination.txt at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Action: Copier le fichier: nonexistent_source.txt vers: destination.txt at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding token type=TokenType.ACTION_ONLY, value=Copier le fichier: nonexistent_source.txt vers: destination.txt, result=('Copier le fichier: nonexistent_source.txt vers: destination.txt',), original=  Action: Copier le fichier: nonexistent_source.txt vers: destination.txt at line 1
[DEBUG] Yielding token: ACTION_ONLY@1:0 'Copier le fichier: nonexistent_source.txt vers: destination.txt' -> '('Copier le fichier: nonexistent_source.txt vers: destination.txt',)'
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le fichier existe at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le fichier existe at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le fichier existe at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le fichier existe at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le fichier existe at line 1
[DEBUG] Yielding token: TEXT@1:0 'Vérifier: Le fichier existe'
[DEBUG] Got 12 tokens
[DEBUG] Grammar: _merge_action_result called with 12 tokens
[DEBUG] Grammar: Token 0: kind=COMMENT, value='# Test with invalid file operations'
[DEBUG] Grammar: Token 1: kind=STEP, value='Test invalid file path'
[DEBUG] Grammar: Token 2: kind=ACTION_ONLY, value='Créer le fichier: /invalid/path/with/special/chars/\0\1\2'
[DEBUG] Grammar: Token 3: kind=TEXT, value='Vérifier: Le fichier existe'
[DEBUG] Grammar: Token 4: kind=EMPTY, value=''
[DEBUG] Grammar: Token 5: kind=STEP, value='Test invalid directory'
[DEBUG] Grammar: Token 6: kind=ACTION_ONLY, value='Créer le dossier: /root/system/directory/that/should/fail'
[DEBUG] Grammar: Token 7: kind=TEXT, value='Vérifier: Le dossier existe'
[DEBUG] Grammar: Token 8: kind=EMPTY, value=''
[DEBUG] Grammar: Token 9: kind=STEP, value='Test invalid file copy'
[DEBUG] Grammar: Token 10: kind=ACTION_ONLY, value='Copier le fichier: nonexistent_source.txt vers: destination.txt'
[DEBUG] Grammar: Token 11: kind=TEXT, value='Vérifier: Le fichier existe'
[DEBUG] Grammar: _merge_action_result returning 12 tokens
Compiled C:\Users\Sventer\OneDrive\Documents\batch testing\src\tests\e2e\ko\invalid_file_operations.shtest -> C:\Users\Sventer\OneDrive\Documents\batch testing\src\tests\e2e\ko\invalid_file_operations.sh
