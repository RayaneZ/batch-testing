ENTRYPOINT DEBUG ACTIVE: src/shtest_compiler/shtest.py loaded
[DEBUG] Loaded patterns: ['step', 'action_result', 'action_only', 'result_only', 'comment']
[DEBUG] Pattern for step: ^(?:Étape|Etape|Step)\s*:\s*(.*)$
[DEBUG] Pattern for action_result: ^Action\s*:\s*(.*?)(?:\s*;\s*(?:R[ée]sultat|Resultat)\s*:\s*(.*)|\s*R[ée]sultat\s*:\s*(.*))$
[DEBUG] Pattern for action_only: ^Action\s*:\s*(.*)$
[DEBUG] Pattern for result_only: ^R[ée]sultat\s*:\s*(.*)$
[DEBUG] Pattern for comment: ^\s*#.*$
[DEBUG] Added STEP tokenizer with pattern: ^(?:Étape|Etape|Step)\s*:\s*(.*)$
[DEBUG] Added ACTION_RESULT tokenizer with pattern: ^Action\s*:\s*(.*?)(?:\s*;\s*(?:R[ée]sultat|Resultat)\s*:\s*(.*)|\s*R[ée]sultat\s*:\s*(.*))$
[DEBUG] Added ACTION_ONLY tokenizer with pattern: ^Action\s*:\s*(.*)$
[DEBUG] Added RESULT_ONLY tokenizer with pattern: ^R[ée]sultat\s*:\s*(.*)$
[DEBUG] Added COMMENT tokenizer with pattern: ^\s*#.*$
[DEBUG] Added FallbackTokenizer
[DEBUG] Parsing text with 8 lines
[DEBUG] Lexing text with 8 lines
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=# Test with invalid SQL syntax at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=# Test with invalid SQL syntax at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=# Test with invalid SQL syntax at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=# Test with invalid SQL syntax at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding token type=TokenType.COMMENT, value=# Test with invalid SQL syntax, result=None, original=# Test with invalid SQL syntax at line 1
[DEBUG] Yielding token: COMMENT@1:0 '# Test with invalid SQL syntax'
[DEBUG] RegexTokenizer.tokenize: Yielding token type=TokenType.STEP, value=Test invalid SQL, result=('Test invalid SQL',), original=Étape: Test invalid SQL at line 1
[DEBUG] Yielding token: STEP@1:0 'Test invalid SQL' -> '('Test invalid SQL',)'
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Action: Exécuter la requête SQL: SELECT * FROM nonexistent_table at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Action: Exécuter la requête SQL: SELECT * FROM nonexistent_table at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding token type=TokenType.ACTION_ONLY, value=Exécuter la requête SQL: SELECT * FROM nonexistent_table, result=('Exécuter la requête SQL: SELECT * FROM nonexistent_table',), original=  Action: Exécuter la requête SQL: SELECT * FROM nonexistent_table at line 1
[DEBUG] Yielding token: ACTION_ONLY@1:0 'Exécuter la requête SQL: SELECT * FROM nonexistent_table' -> '('Exécuter la requête SQL: SELECT * FROM nonexistent_table',)'
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le code de retour est 0 at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le code de retour est 0 at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le code de retour est 0 at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le code de retour est 0 at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le code de retour est 0 at line 1
[DEBUG] Yielding token: TEXT@1:0 'Vérifier: Le code de retour est 0'
[DEBUG] RegexTokenizer.tokenize: Yielding EMPTY token at line 1
[DEBUG] Yielding token: EMPTY@1:0 ''
[DEBUG] RegexTokenizer.tokenize: Yielding token type=TokenType.STEP, value=Test malformed SQL, result=('Test malformed SQL',), original=Étape: Test malformed SQL at line 1
[DEBUG] Yielding token: STEP@1:0 'Test malformed SQL' -> '('Test malformed SQL',)'
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Action: Exécuter la requête SQL: SELECT * FROM table WHERE column = 'unclosed quote at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Action: Exécuter la requête SQL: SELECT * FROM table WHERE column = 'unclosed quote at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding token type=TokenType.ACTION_ONLY, value=Exécuter la requête SQL: SELECT * FROM table WHERE column = 'unclosed quote, result=("Exécuter la requête SQL: SELECT * FROM table WHERE column = 'unclosed quote",), original=  Action: Exécuter la requête SQL: SELECT * FROM table WHERE column = 'unclosed quote at line 1
[DEBUG] Yielding token: ACTION_ONLY@1:0 'Exécuter la requête SQL: SELECT * FROM table WHERE column = 'unclosed quote' -> '("Exécuter la requête SQL: SELECT * FROM table WHERE column = 'unclosed quote",)'
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le code de retour est 0 at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le code de retour est 0 at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le code de retour est 0 at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le code de retour est 0 at line 1
[DEBUG] RegexTokenizer.tokenize: Yielding TEXT token value=Vérifier: Le code de retour est 0 at line 1
[DEBUG] Yielding token: TEXT@1:0 'Vérifier: Le code de retour est 0'
[DEBUG] Got 8 tokens
[DEBUG] Grammar: _merge_action_result called with 8 tokens
[DEBUG] Grammar: Token 0: kind=COMMENT, value='# Test with invalid SQL syntax'
[DEBUG] Grammar: Token 1: kind=STEP, value='Test invalid SQL'
[DEBUG] Grammar: Token 2: kind=ACTION_ONLY, value='Exécuter la requête SQL: SELECT * FROM nonexistent_table'
[DEBUG] Grammar: Token 3: kind=TEXT, value='Vérifier: Le code de retour est 0'
[DEBUG] Grammar: Token 4: kind=EMPTY, value=''
[DEBUG] Grammar: Token 5: kind=STEP, value='Test malformed SQL'
[DEBUG] Grammar: Token 6: kind=ACTION_ONLY, value='Exécuter la requête SQL: SELECT * FROM table WHERE column = 'unclosed quote'
[DEBUG] Grammar: Token 7: kind=TEXT, value='Vérifier: Le code de retour est 0'
[DEBUG] Grammar: _merge_action_result returning 8 tokens
Compiled C:\Users\Sventer\OneDrive\Documents\batch testing\src\tests\e2e\ko\invalid_sql_1.shtest -> C:\Users\Sventer\OneDrive\Documents\batch testing\src\tests\e2e\ko\invalid_sql_1.sh
